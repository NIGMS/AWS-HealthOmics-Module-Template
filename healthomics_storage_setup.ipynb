{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f664edc4-5a8f-46cd-9044-a006075b8fab",
   "metadata": {},
   "source": [
    "# Using HealthOmics Storage with genomic references and readsets\n",
    "### This is the second notebook (2 of 3) in the workshop series and should be run AFTER the ECR setup notebook but BEFORE the workflow notebook. \n",
    "The goal of this notebook is to get you acquainted with HealthOmics Storage.\n",
    "\n",
    "______________________________________________________\n",
    "#### If you complete this notebook you will have:\n",
    "+ Created a Reference Store\n",
    "+ Imported a Reference Genome\n",
    "+ Created a Sequence Store\n",
    "+ Imported FASTQ files\n",
    "\n",
    "## Prerequisites\n",
    "#### Python requirements\n",
    "+ Python >= 3.8\n",
    "#### Packages:\n",
    "+ boto3 >= 1.26.19\n",
    "+ botocore >= 1.29.19\n",
    "#### AWS requirements\n",
    "+ AWS CLI\n",
    "+ You will need the AWS CLI installed and configured in your environment. Supported AWS CLI versions are:\n",
    "    - AWS CLI v2 >= 2.9.3 (Recommended)\n",
    "    - AWS CLI v1 >= 1.27.19\n",
    "    - AWS Region\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE:</b> AWS HealthOmics only allows importing data within the same region. AWS HealthOmics is currently available in Oregon (us-west-2), N. Virginia (us-east-1), Dublin (eu-west-1), London (eu-west-2), Frankfurt (eu-central-1), and Singapore (ap-southeast-1).</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da50683-eaf8-4187-90b9-c99f5e02cb44",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "### Step 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8068eb6f-26a5-4c34-9164-39134f01abd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import necessary libraries and python SDK\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "import boto3\n",
    "import botocore.exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15ee155-80cd-4daf-980a-ac091e4f2ee1",
   "metadata": {},
   "source": [
    "### Step 2. Setup new role\n",
    "For the purposes of this demo, we will use the following policy and trust policy that are rather permissiv. You will need to customize permissions as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9e0ff0-8ab7-41e0-9cd1-41cf226e6d23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define demo policies\n",
    "storage_demo_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:*\",\n",
    "                \"omics:*\",\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "storage_demo_trust_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": [\"sagemaker.amazonaws.com\", \"omics.amazonaws.com\"]\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ab3be3-5724-4f05-8e6b-80528cca2b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will use this as the base name for our role and policy\n",
    "omics_iam_name = 'OmicsStoreDemoRole'\n",
    "\n",
    "# Create the iam client\n",
    "iam = boto3.resource('iam')\n",
    "\n",
    "# Check if the role already exists; if not, create it\n",
    "try:\n",
    "    role = iam.Role(omics_iam_name)\n",
    "    role.load()\n",
    "    \n",
    "except botocore.exceptions.ClientError as ex:\n",
    "    if ex.response[\"Error\"][\"Code\"] == \"NoSuchEntity\":\n",
    "        #Create the role with the corresponding trust policy\n",
    "        role = iam.create_role(\n",
    "            RoleName=omics_iam_name, \n",
    "            AssumeRolePolicyDocument=json.dumps(storage_demo_trust_policy))\n",
    "        \n",
    "        #Create policy\n",
    "        policy = iam.create_policy(\n",
    "            PolicyName='{}-policy'.format(omics_iam_name), \n",
    "            Description=\"Policy for AWS HealthOmics demo\",\n",
    "            PolicyDocument=json.dumps(storage_demo_policy))\n",
    "        \n",
    "        #Attach the policy to the role\n",
    "        policy.attach_role(RoleName=omics_iam_name)\n",
    "    else:\n",
    "        print('Something went wrong, please retry and check your account settings and permissions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f915b6a3-a6f5-43ee-8e05-51fd9117ff00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Retrieve the role arn, which grants AWS HealthOmics the proper permissions to access the resources it needs in your AWS account.\n",
    "def get_role_arn(role_name):\n",
    "    try:\n",
    "        iam = boto3.resource('iam')\n",
    "        role = iam.Role(role_name)\n",
    "        role.load()  # calls GetRole to load attributes\n",
    "    except botocore.exceptions.ClientError:\n",
    "        print(\"Couldn't get role named %s.\"%role_name)\n",
    "        raise\n",
    "    else:\n",
    "        print(role.arn)\n",
    "        return role.arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda382e4-3b8a-45b5-a35d-af935581f90a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Print role name and role arn to be used in store creation and upload\n",
    "role_arn = get_role_arn(omics_iam_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a369d-bc48-4e35-9019-6d8504cd5764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Retrieve the region in which we are running our notebook.\n",
    "region = boto3.session.Session().region_name\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fe51b0-d08b-416c-a193-ddabb568edf6",
   "metadata": {},
   "source": [
    "### Step 3. Setup the HealthOmics client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f6c479-db70-493b-add4-eaa920cfd062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "omics = boto3.client('omics', region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1d559f-9dd6-4689-820b-858c0ffd3f65",
   "metadata": {},
   "source": [
    "### Step 4. Make demo data bucket and move scrnaseq test data to your bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4be675-a28b-4878-aaa2-39d1059e18fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#e.g. s3://nigms-scrnaseq-bucket-demo-data\n",
    "!aws s3 mb s3://[YOUR-BUCKET] #Replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89bc59-27ae-4dfc-8db5-97ef49e1cd56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp s3://aws-genomics-static-us-east-1/workflow_migration_workshop/nfcore-scrnaseq-v2.3.0/samplesheet-2-0.csv s3://[YOUR-BUCKET]\n",
    "!aws s3 cp s3://aws-genomics-static-us-east-1/workflow_migration_workshop/nfcore-scrnaseq-v2.3.0/GRCm38.p6.genome.chr19.fa s3://[YOUR-BUCKET]\n",
    "!aws s3 cp s3://aws-genomics-static-us-east-1/workflow_migration_workshop/nfcore-scrnaseq-v2.3.0/gencode.vM19.annotation.chr19.gtf s3://[YOUR-BUCKET]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030723d8-7af6-408d-b1ad-8dc9f07d9fd6",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "## Reference Store\n",
    "Now we are going to setup a reference store. The reference genome we will be using for this demo is part of nf-core's methylseq test data hosted on their [Github](https://github.com/nf-core/test-datasets/tree/methylseq)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99abe78a-f6f0-4e4b-a74d-d73db9a50d01",
   "metadata": {},
   "source": [
    "### Step 5. Create new reference store\n",
    "Let's create a helper method to retrieve the reference store id and have it return empty if it doesn't exist. There should only be one reference store per region per account.<br>\n",
    "For the purposes of this demo we will be providing inputs from S3, but the reference and sequence stores provide more efficient storage options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39985bde-6997-44d3-8eb0-0bd8f137adce",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE:</b> If this is the first time you've created a reference, you first must create a reference store using the code below. If a reference store already exists the code above will let you know.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782f6164-7fb9-488e-829f-132328a501cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ref_store_id(client=None):\n",
    "    if not client:\n",
    "        client = boto3.client('omics')\n",
    "    resp = client.list_reference_stores(maxResults=10)\n",
    "    list_of_stores = resp.get('referenceStores')\n",
    "    store_id = None\n",
    "    if list_of_stores != None:\n",
    "        # As mentioned above there can only be one store per region\n",
    "        # if there is a store present, it is the first one\n",
    "        store_id = list_of_stores[0].get('id')\n",
    "    return store_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e090f83-737b-44f0-bf2d-ca70f8e93f0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Checking for a reference store in region: {omics.meta.region_name}\")\n",
    "if get_ref_store_id(omics) == None:\n",
    "    response = omics.create_reference_store(name='omics_demo_ref_store')\n",
    "    print(response)\n",
    "else:\n",
    "    print(\"Congratulations, you have an existing reference store!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bee8164-2ff5-49e5-a9c7-077518f65259",
   "metadata": {},
   "source": [
    "### Step 6. Importing references\n",
    "Now we will import a reference using the start_reference_import_job API call. All references in a Reference store must have a unique name. So, we're also going to apply a timestamp to the reference name to ensure that it is unique.\n",
    "\n",
    "The code below uses the reference store we created (or retrieved) and the IAM role we created above. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE:</b> Before running the cell below make sure to replace [YOUR-BUCKET] with name of your S3 bucket.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e8c71d-0189-49dd-b6b7-721550b5a545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set a timestamp\n",
    "dt_fmt = '%Y%m%dT%H%M%S'\n",
    "ts = datetime.now().strftime(dt_fmt)\n",
    "\n",
    "ref_name = f'scrnaseq-demo-ref-{ts}'\n",
    "ref_uri = 's3://[YOUR-BUCKET]/GRCm38.p6.genome.chr19.fa' #Replace [YOUR-BUCKET] with name of your S3 bucket\n",
    "\n",
    "ref_import_job = omics.start_reference_import_job(\n",
    "    referenceStoreId=get_ref_store_id(omics),\n",
    "    roleArn=get_role_arn(omics_iam_name),\n",
    "    sources=[{\n",
    "        'sourceFile': ref_uri,\n",
    "        'name': ref_name,\n",
    "    }])\n",
    "\n",
    "#The import can take up to 5 minutes to complete. We can wait for it to complete using a waiter.\n",
    "print(f\"waiting for job {ref_import_job['id']} to complete\")\n",
    "try:\n",
    "    waiter = omics.get_waiter('reference_import_job_completed')\n",
    "    waiter.wait(referenceStoreId=ref_import_job['referenceStoreId'], id=ref_import_job['id'])\n",
    "\n",
    "    print(f\"job {ref_import_job['id']} complete\")\n",
    "except botocore.exceptions.WaiterError as e:\n",
    "    print(f\"job {ref_import_job['id']} FAILED:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c37a98-7d97-4fa0-b996-15005c444b95",
   "metadata": {
    "tags": []
   },
   "source": [
    "------------------------------------------------------\n",
    "# Sequence Store\n",
    "Now we need to create a sequence store, which is similar to an S3 bucket and holds a set of objects called read sets that can be in various formats (i.e., FASTQ, BAM, CRAM). <br>\n",
    "Again, for the purposes of this demo we will not read in data from the sequence store, but this shows you the process of creating a store and importing read sets if you want to utilize them in your pipeline(s).\n",
    "\n",
    "### Step 7. Create Sequence Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9a3efe-c299-41b8-a01b-3dc8c55480af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set a timestamp\n",
    "dt_fmt = '%Y%m%dT%H%M%S'\n",
    "ts = datetime.now().strftime(dt_fmt)\n",
    "\n",
    "sequence_store_name = f'omics-demo-scrnaseq-store-{ts}'\n",
    "response = omics.create_sequence_store(name=sequence_store_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79168025-37cc-4e1c-a652-98236a9cbd43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create sequence store and print name\n",
    "seqstore = response\n",
    "print(seqstore['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7429aeb-db58-49cc-832c-c5af3b21ba42",
   "metadata": {},
   "source": [
    "### Step 8a. Import Read Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe9169c-80a2-41b8-ae8b-123d10dd7de9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import demo fastq files as read sets into newly created sequence store\n",
    "source1 = 's3://aws-genomics-static-us-east-1/workflow_migration_workshop/nfcore-scrnaseq-v2.3.0/Sample_X_S1_L001_R1_001.fastq.gz'\n",
    "source2 = 's3://aws-genomics-static-us-east-1/workflow_migration_workshop/nfcore-scrnaseq-v2.3.0/Sample_X_S1_L001_R2_001.fastq.gz'\n",
    "\n",
    "readset_import_job = omics.start_read_set_import_job(\n",
    "    roleArn=get_role_arn(omics_iam_name),\n",
    "    sequenceStoreId=seqstore['id'], \n",
    "        sources=[\n",
    "        {\n",
    "            'sourceFiles': {\n",
    "                'source1': source1,\n",
    "                'source2': source2\n",
    "            },\n",
    "            'sourceFileType': 'FASTQ',\n",
    "            'subjectId': 'demo_subject',\n",
    "            'sampleId': 'demo_sample',\n",
    "            'generatedFrom': 'nf-core scrnaseq test data',\n",
    "            'name': 'demo',\n",
    "            'description': 'FASTQ for scrnaseq demo',\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Monitor import and wait for completion using a waiter.\n",
    "print(f\"waiting for job {readset_import_job['id']} to complete\")\n",
    "try:\n",
    "    waiter = omics.get_waiter('read_set_import_job_completed')\n",
    "    waiter.wait(sequenceStoreId=readset_import_job['sequenceStoreId'], id=readset_import_job['id'])\n",
    "\n",
    "    print(f\"job {readset_import_job['id']} complete\")\n",
    "except botocore.exceptions.WaiterError as e:\n",
    "    print(f\"job {readset_import_job['id']} FAILED:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c5898a-48dc-42e0-b300-86eab3066fe1",
   "metadata": {},
   "source": [
    "### Step 8b. Alternatively download samples to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d164af5-2ee9-40e8-81e1-807885df48fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Region e.g. us-east-1\n",
    "#Buckey e.g. s3://nigms-scrnaseq-bucket-demo-data \n",
    "!aws s3 cp --recursive s3://aws-genomics-static-[YOUR-REGION]/workflow_migration_workshop/nfcore-scrnaseq-v2.3.0 s3://[YOUR-BUCKET] #Replace [YOUR-REGION] and [YOUR-BUCKET]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535b1f71-9587-42ad-9392-9b70e43143ce",
   "metadata": {},
   "source": [
    "### Step 9. Update sample sheet with appropriate uris\n",
    "Download the samplesheet file stored in your s3 bucket and replace the paths with the uri3 paths from Step 8a (if using sequence store) or Step 8b if using data copied directly to your s3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81d2837-1cf0-40cd-9bfe-547192b8cec4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 10. Create *input.json* file\n",
    "Use template text below to create *input.json* file and upload into the parameters folder. Make sure to **change [YOUR-BUCKET]** to the name of the S3 bucket you created and stored your data in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a198b8c0-2519-4cdf-a97b-d43cb9a4edf7",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "        \"input\": \"s3://[YOUR-BUCKET]/samplesheet-2-0.csv\",\n",
    "        \"protocol\": \"10XV2\",\n",
    "        \"aligner\": \"star\",\n",
    "        \"fasta\": \"s3://[YOUR-BUCKET]/GRCm38.p6.genome.chr19.fa\",\n",
    "        \"gtf\": \"s3://[YOUR-BUCKET]/gencode.vM19.annotation.chr19.gtf\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c3fd08-10ea-4d46-8187-9f762653a235",
   "metadata": {},
   "source": [
    "## Well done! Now you're ready to create and run a private workflow!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
